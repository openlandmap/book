
---
  format:
    html:
      code-link: true
---

# OpenLandMap STAC 

```{r, include=FALSE, message=FALSE, results='hide'}
ls <- c("rstac", "curl")
new.packages <- ls[!(ls %in% installed.packages()[,"Package"])]
if (length(new.packages)) {
  install.packages(new.packages, repos = "https://cloud.r-project.org")
  # temporarily up to the package's new version is available on CRAN
  remotes::install_github("rolfsimoes/rstac@b-1.0.0-beta")
}
lapply(ls, require, character.only = TRUE)
```

This tutorial will utilize the open-source package `rstac` to explore the STAC static catalog of OpenLandMap. The tutorial aims to demonstrate the functionality of `rstac` in searching for datasets within OpenLandMap's STAC static catalog. 

## Listing layers

Thanks to the STAC functionality and `rstac` package, it is possible to query directly 
which collections are available on the [stac.OpenLandMap.org](http://stac.OpenLandMap.org) (Note: some layers that are available in STAC, might not be available in the front-end/web-GIS):

```{r}
library(rstac)
# Read the OpenLandMap Catalog
olm <- read_stac("http://s3.eu-central-1.wasabisys.com/stac/openlandmap/catalog.json")
olm
```

Users should call the `read_stac()` function to access static STAC catalog data from a specified URL into their environment. This function allows users to read any type of STAC document.

To enumerate all available collections in the OpenLandMap catalog, we can scrutinize the links entry and filter only `"child"` relations that are links to collections. We do this by providing an expression that will be evaluated for each link entry inside the documents' links field:

```{r}
links(olm, rel == "child")
```

For instance, to compile a list of layers with the `title` containing the text `"GLC"` we can use:

```{r}
# Lists links that matches the filter expressions
links(olm, grepl("GLC", title))
```

Let's explore the third link, referencing the `GLC_FCS30D` annual land-cover dynamic monitoring product:

```{r}
# Get the link of the GLC dataset
glc_link <- links(olm, grepl("GLC", title))[[3]]
# Open the link
glc <- link_open(glc_link)
glc
```

Now, let's list its available items. We can use the same function `links()` to access and filter links using an expression. To filter just links that point to items let's use `rel == "item"` expression:

```{r}
# Lists links that point to items
links(glc, rel == "item")
```

At this point, we didn't accessed any `item` we are just seeing links. Links have some metadata that describes them:

```{r}
# Get the first link that matches the filter
glc_link_1 <- links(glc, rel == "item")[[1]]
glc_link_1
```

We can see the list of links metadata in `field(s)` entry above. These fields can be used in filter expressions. Despite links don't have any special metadata like date or bounding box, we can use the `href` field to filter items using the OpenLandMap [file naming convention](https://openlandmap.github.io/book/#the-file-naming-convention). For example, we can use `grepl()` to find the link to an item of a specific date:

```{r}
# Lists links that matches the filter expressions
links(glc, rel == "item", grepl("20200101", href))
```

We can open it by selecting the first item and call `link_open()` function:

```{r}
links(glc, rel == "item", grepl("20200101", href))[[1]] %>% 
  link_open()
```

To open multiple items you can use the function `read_items()`. This functions filters items links and open them in a single document. You still can pass any additional filter:

```{r}
# Read all links with rel == "item" and any additional filter expression
glc_items <- read_items(glc, grepl("200[1-5]0101", href), progress = FALSE)
glc_items
```

The resulting `JSON` document is a `FeatureCollection`. Each element in its `features` property is an `item` that stores metadata on spatio-temporal assets. Here we enumerate all available assets in this document:

```{r}
# Lists all assets name in the document
items_assets(glc_items)
```
Here, `"lc_glc.fcs30d_c_30m_s"` is the name of the main data, while `"qml"` and `"sld"` are style assets to be used in GIS. We can use the `thumbnail` asset to take a preview on the main data:

```{r}
# Get thumbnail URL for each item
thumbnails <- glc_items %>%
  assets_url("thumbnail")
# Plot the thumbnail of the first URL
preview_plot(thumbnails[[1]])
```

The `rstac` package provides many other functions to work with `assets` and `item` documents. Users can also convert `items` to a more familiar format as data frames or simple features to work with the data using their own functions:

```{r}
# Converts the items into a tibble data frame
items_as_tibble(glc_items)
# Converts the items into a sf data frame
items_as_sf(glc_items)
```

## Spatial overlay - Example 1

This section illustrates how to overlay multiple points with Cloud-Optimized GeoTIFFs (COGs). The process involves retrieving COG URLs from STAC items and extracting values at specified coordinates.

To overlay points with COGs, we utilize the `assets_url()` function from `rstac`. This function retrieves the URLs of all COG files, which are then passed to an extraction function.

```{r}
# Get main data URL for each item 
urls <- glc_items %>% 
  assets_url("lc_glc.fcs30d_c_30m_s", append_gdalvsi = TRUE)
```

In the code snippet above, the `append_gdalvsi=TRUE` parameter ensures the addition of `"/vsicurl/"` to each URL, necessary to GDAL open the file.

Next, we define the `extract_xy()` function to extract values from COGs at specific longitude and latitude coordinates.

```{r}
extract_xy = function(urls, lon, lat) {
  requireNamespace("terra", quietly = TRUE)
  requireNamespace("dplyr", quietly = TRUE)
  point <- terra::vect(matrix(c(lon, lat), ncol = 2), crs = "EPSG:4326")
  values <- terra::extract(terra::rast(urls), point, ID = FALSE)
  return(unlist(values, TRUE, FALSE))
}
```

The `extract_xy()` function takes a list of COG URLs, longitude, and latitude as inputs, and returns a vector containing extracted values. Let's extract values at a specific coordinate (e.g., longitude = -35.5, latitude = -9.0).

```{r}
# Extract values for each URL
values <- urls %>% extract_xy(-35.5, -9.0)
values
```

The extracted values might appear as a list of meaningless integers. To interpret these values and assign to it a label, we can utilize the `qml` asset to retrieve information on land cover classes. This is a QML (Quantum Markup Language) file and we can use `xml2` package to find class labels.

First, let's create a function to extract class labels from the QML file based on provided class codes:

```{r}
get_qml_label <- function(qml, codes) {
  # Find the class label in the QML
  class_label <- sapply(codes, function(code) {
    qml %>%
      xml2::xml_find_all(sprintf(".//item[@value='%s']", code)) %>%
      xml2::xml_attr("label")
  })
  return(class_label)
}
```

After creating the function, we can use it to extract class labels from the QML file based on provided class codes. 

```{r}
# Retrieve the URL for the QML file
qml_url <- assets_url(glc_items, "qml")[[1]]
# Read the XML
qml <- xml2::read_xml(qml_url)
# Get the labels
get_qml_label(qml, values)
```

We can store the extracted values and their respective labels in a `tibble`. We can use the tibble derived by `items_as_tibble()` to do this:

```{r}
# Convert the items document into a tibble object
items <- items_as_tibble(glc_items)
items$values <- values
items$labels <- get_qml_label(qml, values)
items
```

## Spatial overlay - Example 2

In this section, we're obtaining municipal boundaries for Brazil using `gadm()` function of `geodata` package. The boundaries are stored as spatial features. In this example, we use the boundary for the municipality of Altamira in Pará state.

```{r}
library(exactextractr)
library(geodata)

# Download Brazilian municipality data
dir <- tempdir() # Change to a non-temporary directory
geodata::geodata_path(dir)
brazil <- geodata::gadm(country = 'BRA', level = 2)
# Select Pará state
para <- brazil[which(grepl("^Pará$", brazil$NAME_1)),]
# Select Altamira municipality
altamira <- brazil[which(grepl("^Altamira$", brazil$NAME_2)),]
# View municipal boundaries for Pará state
plot(para, main = "Altamira-Pará-Brazil")
plot(altamira, col = "gray", add = TRUE)
```

```{r}
links(olm, grepl("FAPAR", title))

fapar_link <- links(olm, grepl("FAPAR", title))[[1]]
fapar_collection <- link_open(fapar_link)
links(fapar_collection, rel == "item")
```

```{r}
fapar_items <- read_items(
  collection = fapar_collection, 
  grepl("20..0601", href), 
  progress = FALSE
)
```

```{r}
items_assets(fapar_items)
```

```{r}
fapar <- fapar_items |> 
  assets_url("fapar_essd.lstm_p95_250m_s", TRUE) |> 
  rast()
fapar
```

```{r}
x <- 0:21
y <- unlist(
  exact_extract(fapar, sf::st_as_sf(altamira), 'quantile', quantiles = 0.02), 
  use.names = FALSE
)

plot(x, y, ylim = c(0.5, 0.7), xlab = "year since 2000")
lines(x, y)

```
